{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenVINO optimizations for Knowledge graphs \n",
    "\n",
    "The goal of this notebook is to showcase performance optimizations for the ConvE knowledge graph embeddings model using the Intel® Distribution of OpenVINO™ Toolkit.\n",
    "The optimizations process contains the following steps:\n",
    "1. Export the trained model to OpenVINO intermediate representation (IR)\n",
    "2. Compare the inference performance with the optimized OpenVINO model\n",
    "\n",
    "The ConvE model we use is an implementation of the paper Convolutional 2D Knowledge Graph Embeddings (https://arxiv.org/abs/1707.01476). The sample dataset was downloaded from: https://github.com/TimDettmers/ConvE/tree/master/countries/countries_S1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windows specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Windows, add the directory that contains cl.exe to the PATH to enable PyTorch to find the\n",
    "# required C++ tools. This code assumes that Visual Studio 2019 is installed in the default\n",
    "# directory. If you have a different C++ compiler, please add the correct path to os.environ[\"PATH\"]\n",
    "# directly. Note that the C++ Redistributable is not enough to run this notebook.\n",
    "\n",
    "# Adding the path to os.environ[\"LIB\"] is not always required - it depends on the system's configuration\n",
    "\n",
    "import sys\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    import distutils.command.build_ext\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "\n",
    "    VS_INSTALL_DIR = r\"C:/Program Files (x86)/Microsoft Visual Studio\"\n",
    "    cl_paths = sorted(list(Path(VS_INSTALL_DIR).glob(\"**/Hostx86/x64/cl.exe\")))\n",
    "    if len(cl_paths) == 0:\n",
    "        raise ValueError(\n",
    "            \"Cannot find Visual Studio. This notebook requires a C++ compiler. If you installed \"\n",
    "            \"a C++ compiler, please add the directory that contains cl.exe to `os.environ['PATH']`.\"\n",
    "        )\n",
    "    else:\n",
    "        # If multiple versions of MSVC are installed, get the most recent version\n",
    "        cl_path = cl_paths[-1]\n",
    "        vs_dir = str(cl_path.parent)\n",
    "        os.environ[\"PATH\"] += f\"{os.pathsep}{vs_dir}\"\n",
    "        # Code for finding the library dirs from\n",
    "        # https://stackoverflow.com/questions/47423246/get-pythons-lib-path\n",
    "        d = distutils.core.Distribution()\n",
    "        b = distutils.command.build_ext.build_ext(d)\n",
    "        b.finalize_options()\n",
    "        os.environ[\"LIB\"] = os.pathsep.join(b.library_dirs)\n",
    "        print(f\"Added {vs_dir} to PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages needed for successful execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch \n",
    "from torch.nn import functional as F, Parameter\n",
    "from torch.nn.init import xavier_normal_\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from openvino.runtime import Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings: Including path to the serialized model files and input data files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "modelpath = Path('models/conve.pt')                                       # Path to the trained model\n",
    "\n",
    "entdatapath = Path('data/countries_S1/kg_training_entids.txt')            # Path to the file containing the entities and entity IDs\n",
    "reldatapath = Path('data/countries_S1/kg_training_relids.txt')            # Path to the file containing the relations and relation IDs\n",
    "testdatapath = Path('data/countries_S1/e1rel_to_e2_ranking_test.json')    # Path to the test data file\n",
    "\n",
    "batch_size = 1                                                            # Batch size\n",
    "emb_dim = 300                                                             # Entity and relation embedding dimensions\n",
    "\n",
    "input_dropout = 0.2                                                       # Input dropout for the model\n",
    "dropout = 0.3                                                             # Dropout for the model\n",
    "feature_map_dropout = 0.2                                                 # Feature map dropout for the model\n",
    "use_bias = True \n",
    "top_k = 2                                                                 # Top K vals to consider from the predictions\n",
    "\n",
    "\n",
    "### Required for OpenVINO conversion\n",
    "output_dir = Path(\"models\")\n",
    "base_model_name = \"conve\"\n",
    "\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Paths where PyTorch, ONNX and OpenVINO IR models will be stored\n",
    "fp32_onnx_path = Path(output_dir / (base_model_name + \"_fp32\")).with_suffix(\".onnx\")\n",
    "fp32_ir_path = fp32_onnx_path.with_suffix(\".xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the ConvE model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model implementation reference: https://github.com/TimDettmers/ConvE\n",
    "class ConvE(torch.nn.Module):\n",
    "    def __init__(self, num_entities, num_relations):\n",
    "        super(ConvE, self).__init__()\n",
    "        # Embedding tables for entity and relations with num_uniq_ent in y-dim, emb_dim in x-dim\n",
    "        self.emb_e = torch.nn.Embedding(num_entities, emb_dim, padding_idx=0)\n",
    "        self.ent_weights_matrix = torch.ones([num_entities, emb_dim], dtype=torch.float64)\n",
    "        self.emb_rel = torch.nn.Embedding(num_relations, emb_dim, padding_idx=0)\n",
    "        self.ne = num_entities\n",
    "        self.nr = num_relations\n",
    "        self.inp_drop = torch.nn.Dropout(input_dropout)\n",
    "        self.hidden_drop = torch.nn.Dropout(dropout)\n",
    "        self.feature_map_drop = torch.nn.Dropout2d(feature_map_dropout)\n",
    "        self.loss = torch.nn.BCELoss()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, (3, 3), 1, 0, bias=use_bias)\n",
    "        self.bn0 = torch.nn.BatchNorm2d(1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(32)\n",
    "        self.ln0 = torch.nn.LayerNorm(emb_dim)\n",
    "        self.register_parameter('b', Parameter(torch.zeros(num_entities)))\n",
    "        self.fc = torch.nn.Linear(16128,emb_dim)\n",
    "    \n",
    "    def init(self):\n",
    "        # Xavier initialization\n",
    "        xavier_normal_(self.emb_e.weight.data)\n",
    "        xavier_normal_(self.emb_rel.weight.data)\n",
    "        \n",
    "    \n",
    "    def forward(self, e1, rel):\n",
    "        e1_embedded= self.emb_e(e1).view(-1, 1, 10, 30)\n",
    "        rel_embedded = self.emb_rel(rel).view(-1, 1, 10, 30)\n",
    "        stacked_inputs = torch.cat([e1_embedded, rel_embedded], 2)\n",
    "\n",
    "        stacked_inputs = self.bn0(stacked_inputs)\n",
    "        x= self.inp_drop(stacked_inputs)\n",
    "        x= self.conv1(x)\n",
    "        x= self.bn1(x)\n",
    "        x= F.relu(x)\n",
    "        x = self.feature_map_drop(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.hidden_drop(x)\n",
    "        x = self.ln0(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.mm(x, self.emb_e.weight.transpose(1,0)) \n",
    "        x = self.hidden_drop(x)\n",
    "        x += self.b.expand_as(x)\n",
    "        pred = torch.nn.functional.softmax(x, dim=1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        super(DataLoader, self).__init__()\n",
    "        \n",
    "        self.ent_path = entdatapath\n",
    "        self.rel_path = reldatapath\n",
    "        self.test_file = testdatapath\n",
    "        self.entity_ids = self.load_data(self.ent_path) \n",
    "        self.rel_ids =  self.load_data(self.rel_path)\n",
    "        self.test_triples_list = self.convert_triples(self.test_file)\n",
    "\n",
    "\n",
    "    def load_data(self, data_path):\n",
    "        item_dict = {}\n",
    "        with open(data_path) as df:\n",
    "            lines = df.readlines()\n",
    "            for line in lines:\n",
    "                name, id = line.strip().split('\\t')\n",
    "                item_dict[name] = int(id)\n",
    "        return item_dict\n",
    "        \n",
    "    def convert_triples(self, data_path):\n",
    "        triples_list = []\n",
    "        with open(data_path) as df:\n",
    "            lines = df.readlines()\n",
    "            for line in lines:\n",
    "                item_dict = json.loads(line.strip())\n",
    "                h = item_dict['e1']\n",
    "                r = item_dict['rel']\n",
    "                t = item_dict['e2_multi1'].split('\\t')\n",
    "                hrt_list = []\n",
    "                hrt_list.append(self.entity_ids[h])\n",
    "                hrt_list.append(self.rel_ids[r])\n",
    "                t_ents = []\n",
    "                for t_idx in t:\n",
    "                    t_ents.append(self.entity_ids[t_idx])\n",
    "                hrt_list.append(t_ents)\n",
    "                triples_list.append(hrt_list)\n",
    "        return triples_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the trained ConvE model\n",
    "We will first evaluate the model performance using PyTorch. The goal is to make sure there are no accuracy differences between the original model inference and the model converted to OpenVINO intermediate representation inference results. \n",
    "Here, we use a simple accuracy metric to evaluate the model performance. However, it is typical to use metrics such as Mean Reciprocal Rank, Hits@10 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader()\n",
    "num_entities =  len(data.entity_ids)\n",
    "num_relations =  len(data.rel_ids)\n",
    "\n",
    "model = ConvE(num_entities, num_relations)\n",
    "model.load_state_dict(torch.load(modelpath))\n",
    "model.eval()\n",
    "\n",
    "pt_inf_times = []\n",
    "\n",
    "triples_list = data.test_triples_list\n",
    "num_test_samples = len(triples_list)\n",
    "pt_acc = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    test_sample = triples_list[i]\n",
    "    h,r,t = test_sample\n",
    "    start_time = time.time()\n",
    "    logits = model.forward(torch.tensor(h), torch.tensor(r))\n",
    "    end_time = time.time()\n",
    "    pt_inf_times.append(end_time-start_time)\n",
    "    score, pred = torch.topk(logits, top_k, 1)\n",
    "    \n",
    "    gt = np.array(sorted(t))\n",
    "    pred = np.array(sorted(pred[0].cpu().detach()))\n",
    "    pt_acc += accuracy_score(gt, pred)\n",
    "\n",
    "avg_pt_time = np.mean(pt_inf_times)*1000\n",
    "print(f'Average time taken for inference: {avg_pt_time} ms')\n",
    "print(f'Mean accuracy of the model on the test dataset: {pt_acc/num_test_samples}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the trained PyTorch model to ONNX format\n",
    "To evaluate performance with OpenVINO, we can either convert the trained PyTorch model to an intermediate representation (IR) format or to an ONNX representation. In this notebook, we use the ONNX format.\n",
    "For more details on model optimization, refer to: https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Converting the trained conve model to ONNX format')\n",
    "torch.onnx.export(model, (torch.tensor(1), torch.tensor(1)), fp32_onnx_path, verbose=False, opset_version=11, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model performance with OpenVINO\n",
    "Now, we evaluate the model performance with the OpenVINO framework. In order to do so, we make three main API calls:\n",
    "1. Initialize the Inference engine with Core()\n",
    "2. Load the model with read_model()\n",
    "3. Compile the model with compile_model()\n",
    "\n",
    "The model can then be inferred on using by using the create_infer_request() API call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "ir_net = ie.read_model(model=fp32_onnx_path)\n",
    "compiled_model = ie.compile_model(model=ir_net)\n",
    "output_layer = compiled_model.output(0)\n",
    "request = compiled_model.create_infer_request()\n",
    "\n",
    "ov_acc = 0.0\n",
    "ov_inf_times = []\n",
    "for i in range(num_test_samples):\n",
    "    test_sample = triples_list[i]\n",
    "    h,r,t = test_sample\n",
    "    start_time = time.time()\n",
    "    request.infer(inputs={'input.1': h,'input.2': r})\n",
    "    end_time = time.time()\n",
    "    result = request.get_output_tensor(output_layer.index).data\n",
    "    ov_inf_times.append(end_time-start_time)\n",
    "    top_k_idx = list(np.argpartition(result[0], -top_k)[-top_k:])\n",
    "    \n",
    "    gt = np.array(sorted(t))\n",
    "    pred = np.array(sorted(top_k_idx))\n",
    "    ov_acc += accuracy_score(gt, pred)\n",
    "\n",
    "\n",
    "avg_ov_time = np.mean(ov_inf_times)*1000\n",
    "print(f'Average time taken for inference: {avg_ov_time} ms')\n",
    "print(f'Mean accuracy of the model on the test dataset: {ov_acc/num_test_samples}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, we print the platform specific speedup obtained through OpenVINO graph optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Speedup with OpenVINO optimizations: {round(float(avg_pt_time)/float(avg_ov_time),2)} X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. Convolutional 2D Knowledge Graph Embeddings, Tim Dettmers et al. (https://arxiv.org/abs/1707.01476)\n",
    "2. Model implementation: https://github.com/TimDettmers/ConvE"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "abe8502b4f19c33cf2db7328db8943f9573038641d3457317a81edba9a7387a1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('openvino_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
